{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.填充\n",
    "\n",
    "* 为何需要填充？各图片数据的高和宽、各序列信号的长度等，维度长度可能各不相同，为方便并行计算，需要将不同长度的数据扩张为相同数据。\n",
    "* 复制操作可以扩展数据长度，但会破坏原有的数据的结构\n",
    "* 解决方案是，在需要补充长度的开始或结束处填充足够数量的特定值（一般是无意义的值，如0），这种操作叫填充"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "假设有两个句子，并分别编码为：\n",
    "* \"I like the weather today.\" -> \\[1,2,3,4,5,6\\]\n",
    "* \"So do I.\" -> \\[7,8,1,6\\]\n",
    "\n",
    "为保持编码长度一致，将第二个句子填充为\\[7,8,1,6,0,0\\]\n",
    "此时再进行堆叠合并shape为\\[2,6\\]的张量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "进行填充的关键函数：`tf.pad(x,paddings)`:\n",
    "* paddings是包含了多个`[左边填充个数,右边填充个数]`的List。如`[[0,0],[2,1],[1,2]]`表示第一个维度不填充，第二个维度左边起始填充2个单元，右边结束处填充1个单元，第三个维度左边起始填充1个单元，右边结束处填充2个单元"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([7 8 1 6 0 0], shape=(6,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2 3 4 5 6]\n",
      " [7 8 1 6 0 0]], shape=(2, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant([1,2,3,4,5,6]) # 第一个句子\n",
    "b=tf.constant([7,8,1,6]) # 第二个句子\n",
    "b=tf.pad(b,[[0,2]]) # 句子末尾填充2个0\n",
    "print(b)\n",
    "c=tf.stack([a,b],axis=0) # 堆叠合并形成2个样本\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.NLP中填充例子\n",
    "* 自然语言处理中，数据集中的句子有长有短，一般选取能够覆盖大部分句子长度的阈值，如80个单词。\n",
    "* 对于小于80个单词的句子，末尾填充0；大于80个单词的句子，截断尾部。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/julianApps/miniconda3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/julianApps/miniconda3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000, 80) (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "# 以IMDB数据集的加载为例\n",
    "total_words=10000 # 设定词汇量大小\n",
    "max_review_len=80 # 最大句子长度\n",
    "embedding_len=100 # 词向量长度\n",
    "# 加载IMDB数据集\n",
    "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.imdb.load_data(num_words=total_words)\n",
    "print(x_train.shape,x_test.shape)\n",
    "# 将句子填充或截断到相同长度，设置为末尾填充和末尾截断方式\n",
    "x_train=tf.keras.preprocessing.sequence.pad_sequences(x_train,maxlen=max_review_len,truncating='post',padding='post')\n",
    "x_test=tf.keras.preprocessing.sequence.pad_sequences(x_test,maxlen=max_review_len,truncating='post',padding='post')\n",
    "print(x_train.shape,x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.图像中多个维度填充例子\n",
    "\n",
    "如下图，是一个`[[0,0],[2,2],[2,2],[0,0]]`填充方案:\n",
    "\n",
    "![](https://github.com/zfhxi/Learn_tensorflow/blob/master/ch05-TensorFlow%e8%bf%9b%e9%98%b6/img/03.png?raw=true)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "x=tf.random.normal([4,28,28,1])\n",
    "x_after_pad=tf.pad(x,[[0,0],[2,2],[2,2],[0,0]])\n",
    "print(x_after_pad.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.复制\n",
    "同a04.08中复制数据一致，此处仅再做回顾："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "x=tf.random.normal([4,32,32,3])\n",
    "x_after_tile=tf.tile(x,[2,3,3,1]) # 图片数据复制一份，高宽各复制2份\n",
    "print(x_after_tile.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "pid=os.getpid()\n",
    "!kill -9 $pid\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}