{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets as datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.前言\n",
    ">基于a04.10修改，保持原有的说明\n",
    "\n",
    "目标：实现如下网络\n",
    "\n",
    "$$\\mathrm{out}=\\mathrm{ReLU}_3(\\mathrm{ReLU}_2\\lgroup\\mathrm{ReLU}_1(X@W_1+b_1)@W_2+b_2\\rgroup@W_3+b_3)$$\n",
    "\n",
    "数据集：MNIST\n",
    "输入节点数为784，第一层输出节点为256，第二层输出节点为128，第三层输出节点为10\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.加载数据\n",
    "将shape为\\[b,28,28\\] -> \\[b,28*28\\]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    # 调用此函数会自动传入x，y\n",
    "    # 标准化到0~1\n",
    "    x=tf.cast(x,dtype=tf.float32)/255.\n",
    "    x=tf.reshape(x,[-1,28*28]) # 打平\n",
    "    y=tf.cast(y,dtype=tf.int32) # 转换成整型张量\n",
    "    y=tf.one_hot(y,depth=10) # 进行one-hot编码\n",
    "    return x,y\n",
    "\n",
    "def load_data():\n",
    "    # 加载MNIST\n",
    "    (x,y),(x_val,y_val)=datasets.mnist.load_data()\n",
    "    batchsz=512\n",
    "    # 构建数据集对象\n",
    "    train_dataset=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    train_dataset=train_dataset.shuffle(1000)\n",
    "    #批量训练\n",
    "    train_dataset=train_dataset.batch(batchsz)\n",
    "    train_dataset=train_dataset.map(preprocess)\n",
    "    train_dataset=train_dataset.repeat(20)\n",
    "\n",
    "    # 加载验证/测试集\n",
    "    val_dataset=tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "    val_dataset=val_dataset.shuffle(1000).batch(batchsz).map(preprocess)\n",
    "    return train_dataset,val_dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.创建并初始化非线性层的张量参数\n",
    "\n",
    "> `tf.random.truncated_normal`从截断的正态分布中输出随机值。 生成的值服从具有指定平均值和标准偏差的正态分布，如果生成的值大于平均值2个标准偏差的值则丢弃重新选择。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def init_paramaters():\n",
    "    # 每个张量需要被优化，所以使用tf.Variable\n",
    "    # 第一层\n",
    "    W1=tf.Variable(tf.random.truncated_normal([784,256],stddev=.1))\n",
    "    b1=tf.Variable(tf.zeros([256]))\n",
    "\n",
    "    # 第二层\n",
    "    W2=tf.Variable(tf.random.truncated_normal([256,128],stddev=.1))\n",
    "    b2=tf.Variable(tf.zeros([128]))\n",
    "\n",
    "    # 输出层\n",
    "    W3=tf.Variable(tf.random.truncated_normal([128,10],stddev=.1))\n",
    "    b3=tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    return W1,b1,W2,b2,W3,b3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.前向"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def my_forward(x,W1,b1,W2,b2,W3,b3):\n",
    "    # 第一层计算，bx784 @ 784x256 + 256 => bx256 + 256 => bx256 + bx256\n",
    "    h1=x@W1+tf.broadcast_to(b1,[x.shape[0],256])\n",
    "    h1=tf.nn.relu(h1) # 激活函数处理\n",
    "\n",
    "    # 第二层计算，bx256 @ 256x128 + 128 => bx128 + 128 => bx128 + bx128\n",
    "    h2=h1@W2+b2\n",
    "    h2=tf.nn.relu(h2) # 激活函数处理\n",
    "\n",
    "    # 输出层计算，bx128 @ 128x10 + 10 => bx10 + 10 => bx10 + bx10\n",
    "    out=h2@W3+b3\n",
    "\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.误差计算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def mse_loss(y,p):\n",
    "    # mse = mean(sum(y-p)^2)\n",
    "    loss=tf.square(y-p)\n",
    "    loss=tf.reduce_mean(loss)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.求梯度"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 全局变量\n",
    "losses=list()\n",
    "accs=list()\n",
    "\n",
    "def train_epoch(train_dataset,val_dataset,W1,b1,W2,b2,W3,b3,epoch,lr=0.001):\n",
    "    for step,(x,y) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            out=my_forward(x,W1,b1,W2,b2,W3,b3)\n",
    "            loss=mse_loss(y,out)\n",
    "\n",
    "        # 自动梯度，需要求梯度的张量有[W1,b1,W2,b2,W3,b3]\n",
    "        grads=tape.gradient(loss,[W1,b1,W2,b2,W3,b3])\n",
    "        # 梯度更新，assign_sub将当前值减去参数值（原地更新）\n",
    "        for p,g in zip([W1,b1,W2,b2,W3,b3],grads):\n",
    "            p.assign_sub(lr*g)\n",
    "        if step % 80 == 0:\n",
    "            print(f'epoch[{epoch}],step[{step}],loss: {float(loss)}')\n",
    "            global losses\n",
    "            losses.append(float(loss))\n",
    "        # 进行验证\n",
    "        if step % 80 ==0:\n",
    "            # evaluate/test\n",
    "            total, total_correct = 0., 0\n",
    "            for x,y in val_dataset:\n",
    "                out=my_forward(x,W1,b1,W2,b2,W3,b3)\n",
    "                pred=tf.argmax(out,axis=1) # 寻找每个样本的最大得分类别\n",
    "                num_y=tf.argmax(y,axis=1) # 将one-hot转为数字\n",
    "                correct=tf.equal(pred,num_y)\n",
    "                # bool -> int -> numpy\n",
    "                total_correct+=tf.reduce_sum(tf.cast(correct,dtype=tf.int32)).numpy()\n",
    "                total+=x.shape[0]\n",
    "\n",
    "            print(f'epoch[{epoch}],step[{step}],acc: {total_correct/total}')\n",
    "            global accs\n",
    "            accs.append(total_correct/total)\n",
    "    return loss.numpy()\n",
    "\n",
    "def run(epochs):\n",
    "    losses=[]\n",
    "    train_dataset,val_dataset=load_data()\n",
    "    W1,b1,W2,b2,W3,b3=init_paramaters()\n",
    "    for epoch in range(epochs):\n",
    "        loss=train_epoch(train_dataset,val_dataset,W1,b1,W2,b2,W3,b3,epoch=epoch,lr=0.001)\n",
    "        # print(f'epoch[{epoch}]-loss: {loss}')\n",
    "        # losses.append((loss))\n",
    "    # 绘制曲线\n",
    "    # xx=[i for i in range(0,epochs)]\n",
    "    # plt.plot(xx,losses,color='b',marker='s',label='训练')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('MSE')\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0],step[0],loss: 0.39274463057518005\n",
      "epoch[0],step[0],evaluate acc: 0.0906\n",
      "epoch[0],step[80],loss: 0.20164796710014343\n",
      "epoch[0],step[80],evaluate acc: 0.1077\n",
      "epoch[0],step[160],loss: 0.19150324165821075\n",
      "epoch[0],step[160],evaluate acc: 0.1196\n",
      "epoch[0],step[240],loss: 0.17781183123588562\n",
      "epoch[0],step[240],evaluate acc: 0.1292\n",
      "epoch[0],step[320],loss: 0.17328818142414093\n",
      "epoch[0],step[320],evaluate acc: 0.1396\n",
      "epoch[0],step[400],loss: 0.17016005516052246\n",
      "epoch[0],step[400],evaluate acc: 0.1515\n",
      "epoch[0],step[480],loss: 0.16404065489768982\n",
      "epoch[0],step[480],evaluate acc: 0.1614\n",
      "epoch[0],step[560],loss: 0.15450550615787506\n",
      "epoch[0],step[560],evaluate acc: 0.1737\n",
      "epoch[0],step[640],loss: 0.15469805896282196\n",
      "epoch[0],step[640],evaluate acc: 0.186\n",
      "epoch[0],step[720],loss: 0.15114425122737885\n",
      "epoch[0],step[720],evaluate acc: 0.1986\n",
      "epoch[0],step[800],loss: 0.14847564697265625\n",
      "epoch[0],step[800],evaluate acc: 0.2094\n",
      "epoch[0],step[880],loss: 0.1454223245382309\n",
      "epoch[0],step[880],evaluate acc: 0.2212\n",
      "epoch[0],step[960],loss: 0.14397332072257996\n",
      "epoch[0],step[960],evaluate acc: 0.2329\n",
      "epoch[0],step[1040],loss: 0.13770022988319397\n",
      "epoch[0],step[1040],evaluate acc: 0.2435\n",
      "epoch[0],step[1120],loss: 0.13461916148662567\n",
      "epoch[0],step[1120],evaluate acc: 0.2553\n",
      "epoch[0],step[1200],loss: 0.12801945209503174\n",
      "epoch[0],step[1200],evaluate acc: 0.267\n",
      "epoch[0],step[1280],loss: 0.13081268966197968\n",
      "epoch[0],step[1280],evaluate acc: 0.2773\n",
      "epoch[0],step[1360],loss: 0.13064101338386536\n",
      "epoch[0],step[1360],evaluate acc: 0.288\n",
      "epoch[0],step[1440],loss: 0.1317182332277298\n",
      "epoch[0],step[1440],evaluate acc: 0.2972\n",
      "epoch[0],step[1520],loss: 0.11970414966344833\n",
      "epoch[0],step[1520],evaluate acc: 0.3075\n",
      "epoch[0],step[1600],loss: 0.12310681492090225\n",
      "epoch[0],step[1600],evaluate acc: 0.3166\n",
      "epoch[0],step[1680],loss: 0.11613357067108154\n",
      "epoch[0],step[1680],evaluate acc: 0.3282\n",
      "epoch[0],step[1760],loss: 0.11274091899394989\n",
      "epoch[0],step[1760],evaluate acc: 0.3357\n",
      "epoch[0],step[1840],loss: 0.11613253504037857\n",
      "epoch[0],step[1840],evaluate acc: 0.3441\n",
      "epoch[0],step[1920],loss: 0.11627354472875595\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-73472aa990df>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-5a08658b1897>\u001B[0m in \u001B[0;36mrun\u001B[0;34m(epochs)\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[0mW1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mW2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mW3\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb3\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minit_paramaters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 43\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mval_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mW1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mW2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mW3\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mb3\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.001\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     44\u001B[0m         \u001B[0;31m# print(f'epoch[{epoch}]-loss: {loss}')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m         \u001B[0;31m# losses.append((loss))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-5a08658b1897>\u001B[0m in \u001B[0;36mtrain_epoch\u001B[0;34m(train_dataset, val_dataset, W1, b1, W2, b2, W3, b3, epoch, lr)\u001B[0m\n\u001B[1;32m     28\u001B[0m                 \u001B[0mcorrect\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mequal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpred\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnum_y\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m                 \u001B[0;31m# bool -> int -> numpy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m                 \u001B[0mtotal_correct\u001B[0m\u001B[0;34m+=\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduce_sum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcorrect\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m                 \u001B[0mtotal\u001B[0m\u001B[0;34m+=\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/julianApps/miniconda3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/julianApps/miniconda3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36mcast\u001B[0;34m(x, dtype, name)\u001B[0m\n\u001B[1;32m    787\u001B[0m       \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"x\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    788\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_dtype\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mbase_type\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 789\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbase_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    790\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbase_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_floating\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    791\u001B[0m       \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwarn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Casting complex to real discards imaginary part.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/julianApps/miniconda3/envs/tf38/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001B[0m in \u001B[0;36mcast\u001B[0;34m(x, DstT, Truncate, name)\u001B[0m\n\u001B[1;32m   1954\u001B[0m     \u001B[0mA\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mDstT\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1955\u001B[0m   \"\"\"\n\u001B[0;32m-> 1956\u001B[0;31m   \u001B[0m_ctx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_context\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1957\u001B[0m   \u001B[0mtld\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_thread_local_data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1958\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "run(epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x=[i*80 for i in range(len(losses))]\n",
    "plt.plot(x,losses,color='C0',marker='s',label='训练')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Step')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x,accs,color='C1',marker='s',label='测试')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Step')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "pid=os.getpid()\n",
    "!kill -9 $pid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}