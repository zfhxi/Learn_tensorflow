{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "在网络训练的过程中，通过Web端远程监控网络的训练进度，可视化网络的训练结果，对于提高开发效率和实现远程监控是非常重要的。TensorFlow提供了一个专门的可视化工具，叫做TensorBoard，它通过TensorFlow将监控数据写入到文件系统，并利用Web后端监控对应的文件目录，从而可以允许用户从远程查看网络的监控数据\n",
    "\n",
    "要使用tensorboard工具监控网络训练进度，要从模型端和浏览器端入手"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.模型端\n",
    "\n",
    "模型端需要创建写入监控数据的Summary类，并指定监控数据的写入目录："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "log_dir='./log'\n",
    "summary_writer=tf.summary.create_file_writer(log_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "例如在前向计算完后，对于误差这种数据，需要监控，并赋予一个ID\n",
    "\n",
    "下面结合之前构建的网络做例子来演示："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0]-step[0] loss:0.1403273046016693\n",
      "epoch[0]-step[500] loss:0.020966259762644768\n",
      "epoch[0]-step[1000] loss:0.003918889909982681\n",
      "epoch[0]-step[1500] loss:0.0020578422117978334\n",
      "epoch[0]-step[2000] loss:0.0012696660123765469\n",
      "epoch[1]-step[0] loss:0.0008957092650234699\n",
      "epoch[1]-step[500] loss:0.0006887515773996711\n",
      "epoch[1]-step[1000] loss:0.0005277349846437573\n",
      "epoch[1]-step[1500] loss:0.0004293204110581428\n",
      "epoch[1]-step[2000] loss:0.0003579477488528937\n",
      "epoch[2]-step[0] loss:0.0003179462219122797\n",
      "epoch[2]-step[500] loss:0.0002832511381711811\n",
      "epoch[2]-step[1000] loss:0.00025106361135840416\n",
      "epoch[2]-step[1500] loss:0.0002210118982475251\n",
      "epoch[2]-step[2000] loss:0.00019726170285139233\n",
      "epoch[3]-step[0] loss:0.00019218225497752428\n",
      "epoch[3]-step[500] loss:0.00017839492647908628\n",
      "epoch[3]-step[1000] loss:0.00016368877550121397\n",
      "epoch[3]-step[1500] loss:0.00014910355093888938\n",
      "epoch[3]-step[2000] loss:0.0001413038553437218\n",
      "epoch[4]-step[0] loss:0.00013447608216665685\n",
      "epoch[4]-step[500] loss:0.0001280965661862865\n",
      "epoch[4]-step[1000] loss:0.00011984530283370987\n",
      "epoch[4]-step[1500] loss:0.00011509048636071384\n",
      "epoch[4]-step[2000] loss:0.0001108189535443671\n",
      "epoch[5]-step[0] loss:0.00010934430611087009\n",
      "epoch[5]-step[500] loss:0.00010886443487834185\n",
      "epoch[5]-step[1000] loss:0.00010212964116362855\n",
      "epoch[5]-step[1500] loss:0.0001016187306959182\n",
      "epoch[5]-step[2000] loss:9.691811283119023e-05\n",
      "epoch[6]-step[0] loss:9.502940520178527e-05\n",
      "epoch[6]-step[500] loss:9.341901750303805e-05\n",
      "epoch[6]-step[1000] loss:9.108877566177398e-05\n",
      "epoch[6]-step[1500] loss:9.206920367432758e-05\n",
      "epoch[6]-step[2000] loss:8.673363481648266e-05\n",
      "epoch[7]-step[0] loss:8.585239993408322e-05\n",
      "epoch[7]-step[500] loss:8.472398621961474e-05\n",
      "epoch[7]-step[1000] loss:8.39378553791903e-05\n",
      "epoch[7]-step[1500] loss:8.368678390979767e-05\n",
      "epoch[7]-step[2000] loss:7.940494833746925e-05\n",
      "epoch[8]-step[0] loss:8.219711162382737e-05\n",
      "epoch[8]-step[500] loss:7.938921044114977e-05\n",
      "epoch[8]-step[1000] loss:7.910325075499713e-05\n",
      "epoch[8]-step[1500] loss:8.017711661523208e-05\n",
      "epoch[8]-step[2000] loss:7.53844651626423e-05\n",
      "epoch[9]-step[0] loss:7.617280789418146e-05\n",
      "epoch[9]-step[500] loss:7.542583625763655e-05\n",
      "epoch[9]-step[1000] loss:7.482695946237072e-05\n",
      "epoch[9]-step[1500] loss:7.66715093050152e-05\n",
      "epoch[9]-step[2000] loss:7.337112037930638e-05\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x,y):\n",
    "    # 调用此函数会自动传入x，y\n",
    "    # 标准化到0~1\n",
    "    x=tf.cast(x,dtype=tf.float32)/255.\n",
    "    x=tf.reshape(x,[-1,28*28]) # 打平\n",
    "    y=tf.cast(y,dtype=tf.int32) # 转换成整型张量\n",
    "    y=tf.one_hot(y,depth=10) # 进行one-hot编码\n",
    "    return x,y\n",
    "\n",
    "def load_data():\n",
    "    # 加载MNIST\n",
    "    (x,y),(x_val,y_val)=keras.datasets.mnist.load_data()\n",
    "    batchsz=512\n",
    "    # 构建数据集对象\n",
    "    train_dataset=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    train_dataset=train_dataset.shuffle(1000)\n",
    "    #批量训练\n",
    "    train_dataset=train_dataset.batch(batchsz)\n",
    "    train_dataset=train_dataset.map(preprocess)\n",
    "    train_dataset=train_dataset.repeat(20)\n",
    "\n",
    "    # 加载验证/测试集\n",
    "    val_dataset=tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "    val_dataset=val_dataset.shuffle(1000).batch(batchsz).map(preprocess)\n",
    "    return train_dataset,val_dataset\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1=keras.layers.Dense(256,activation='relu')\n",
    "        self.fc2=keras.layers.Dense(128,activation='relu')\n",
    "        self.fc3=keras.layers.Dense(10,activation='relu')\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x=self.fc1(inputs)\n",
    "        x=self.fc2(x)\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model=MyModel()\n",
    "model.build(input_shape=(None,28*28))\n",
    "\n",
    "optimizer=keras.optimizers.RMSprop(0.001)\n",
    "train_dataset,val_dataset=load_data()\n",
    "loss_meter=keras.metrics.Mean() # 1.新建平均测量器\n",
    "\n",
    "for epoch in range(10):\n",
    "    for step,(x,y) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            out=model(x)\n",
    "            loss=tf.losses.MSE(y,out)\n",
    "            mean_mse_loss=tf.reduce_mean(loss)\n",
    "            loss_meter.update_state(loss) # 2.写入数据，记录采样的数据\n",
    "            '''\n",
    "            summary记录\n",
    "            '''\n",
    "            with summary_writer.as_default(): # 写入环境\n",
    "                # 当前时间戳step上的loss写入到id为train-loss数据库中\n",
    "                tf.summary.scalar('train-loss',float(mean_mse_loss),step=step)\n",
    "        grads=tape.gradient(mean_mse_loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "\n",
    "        if step%500==0:\n",
    "            print(f'epoch[{epoch}]-step[{step}] loss:{loss_meter.result()}') # 3.读取统计信息\n",
    "            loss_meter.reset_states() # 4.清零测量器"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.浏览器端\n",
    "为了查看可视化的这些数据，需要在终端运行`tensorboard --logdir path`\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir log --host=0.0.0.0\n",
    "```\n",
    "\n",
    "查看结果如下：\n",
    "\n",
    "![](https://github.com/zfhxi/Learn_tensorflow/blob/master/ch08-Keras%E9%AB%98%E5%B1%82%E6%8E%A5%E5%8F%A3/img/01.png?raw=true)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "pid=os.getpid()\n",
    "!kill -9 $pid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}