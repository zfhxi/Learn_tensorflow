{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers,datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.前言\n",
    "\n",
    "Keras库分为前段和后段：\n",
    "* 后端调用现有的深度学习框架实现底层运算，如Theano、CNTK、TensorFlow\n",
    "* 前端指前端接口，是Keras抽象过的一组统一接口函数。\n",
    "\n",
    "在TensorFlow 2版本中，Keras已被实现在tf.keras子模块中，并且只以TensorFlow为后端做运算。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Keras提供了一系列高层的神经网络相关类和函数，如经典数据集加载函数、网络层类、模型容器、损失函数类、优化器类、经典模型类等。\n",
    "\n",
    "## 1.管理数据集\n",
    "对于经典数据集，通过一行代码即可下载、管理、加载数据集，这些数据集包括Boston房价预测数据集、CIFAR图片数据集、MNIST/FashionMNIST手写数字图片数据集、IMDB文本数据集等。\n",
    "\n",
    "关于数据集的加载、管理的实例可见[a05.07-经典数据集加载.ipynb](https://nbviewer.jupyter.org/github/zfhxi/Learn_tensorflow/blob/master/ch05-TensorFlow%E8%BF%9B%E9%98%B6/a05.07-%E7%BB%8F%E5%85%B8%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8A%A0%E8%BD%BD.ipynb)\n",
    "<br>总结步骤为如下（以mnist数据集为例）："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (60000, 28, 28)\n",
      "y: (60000,)\n",
      "x_test: (10000, 28, 28)\n",
      "y_test: (10000,)\n",
      "<TensorSliceDataset shapes: ((28, 28), ()), types: (tf.uint8, tf.uint8)>\n",
      "<ShuffleDataset shapes: ((28, 28), ()), types: (tf.uint8, tf.uint8)>\n",
      "<BatchDataset shapes: ((None, 28, 28), (None,)), types: (tf.uint8, tf.uint8)>\n",
      "<MapDataset shapes: ((None, 784), (None, 10)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1.数据加载\n",
    "'''\n",
    "# 加载MNIST数据集\n",
    "(x,y),(x_test,y_test)=datasets.mnist.load_data()\n",
    "print(f'x: {x.shape}\\ny: {y.shape}\\nx_test: {x_test.shape}\\ny_test: {y_test.shape}')\n",
    "\n",
    "# 转换成Dataset对象\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)) # 构建 Dataset 对象\n",
    "print(train_db)\n",
    "\n",
    "'''\n",
    "2.随机打散\n",
    "'''\n",
    "train_db=train_db.shuffle(buffer_size=10000) # 随机打散样本，不会打乱样本与标签映射关系\n",
    "print(train_db)\n",
    "\n",
    "'''\n",
    "3.批训练\n",
    "'''\n",
    "train_db=train_db.batch(128) # 设置批训练，batch size为128\n",
    "print(train_db)\n",
    "\n",
    "'''\n",
    "4.预处理\n",
    "'''\n",
    "def preprocess(x,y):\n",
    "    # 调用此函数会自动传入x，y\n",
    "    # 标准化到0~1\n",
    "    x=tf.cast(x,dtype=tf.float32)/255.\n",
    "    x=tf.reshape(x,[-1,28*28]) # 打平\n",
    "    y=tf.cast(y,dtype=tf.int32) # 转换成整型张量\n",
    "    y=tf.one_hot(y,depth=10) # 进行one-hot编码\n",
    "    return x,y\n",
    "train_db=train_db.map(preprocess)\n",
    "print(train_db)\n",
    "\n",
    "'''\n",
    "5.循环训练\n",
    "'''\n",
    "epochs=1\n",
    "def do(x,y):\n",
    "    pass\n",
    "\n",
    "for step,(x,y) in enumerate(train_db):\n",
    "    do(x,y)\n",
    "# or\n",
    "for x,y in train_db:\n",
    "    do(x,y)\n",
    "# generally\n",
    "for epoch in range(epochs):\n",
    "    for step,(x,y) in enumerate(train_db):\n",
    "        do(x,y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "回顾之前加载、管理数据集的操作："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**a03.01**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x,y),(x_val,y_val)=datasets.mnist.load_data()\n",
    "\n",
    "# 转换为tensor格式并分批\n",
    "x=tf.convert_to_tensor(x,dtype=tf.float32)/255.\n",
    "y=tf.convert_to_tensor(y,dtype=tf.int32)\n",
    "y=tf.one_hot(y,depth=10)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_dataset=train_dataset.batch(200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**a04.10**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # 加载MNIST\n",
    "    (x,y),(x_val,y_val)=datasets.mnist.load_data()\n",
    "    # 转换为浮点张量，并缩放到（0～1）\n",
    "    x=tf.convert_to_tensor(x,dtype=tf.float32)/255.\n",
    "    # 转换为整型张量\n",
    "    y=tf.convert_to_tensor(y,dtype=tf.int32)\n",
    "    # one-hot编码\n",
    "    y=tf.one_hot(y,depth=10)\n",
    "    # 改变视图\n",
    "    x=tf.reshape(x,[-1,28*28])\n",
    "\n",
    "    # 构建数据集对象\n",
    "    train_dataset=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    #批量训练\n",
    "    train_dataset=train_dataset.batch(200)\n",
    "    return train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**a05.08**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    # 调用此函数会自动传入x，y\n",
    "    # 标准化到0~1\n",
    "    x=tf.cast(x,dtype=tf.float32)/255.\n",
    "    x=tf.reshape(x,[-1,28*28]) # 打平\n",
    "    y=tf.cast(y,dtype=tf.int32) # 转换成整型张量\n",
    "    y=tf.one_hot(y,depth=10) # 进行one-hot编码\n",
    "    return x,y\n",
    "\n",
    "def load_data():\n",
    "    # 加载MNIST\n",
    "    (x,y),(x_val,y_val)=datasets.mnist.load_data()\n",
    "    batchsz=512\n",
    "    # 构建数据集对象\n",
    "    train_dataset=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    train_dataset=train_dataset.shuffle(1000)\n",
    "    #批量训练\n",
    "    train_dataset=train_dataset.batch(batchsz)\n",
    "    train_dataset=train_dataset.map(preprocess)\n",
    "    train_dataset=train_dataset.repeat(20)\n",
    "\n",
    "    # 加载验证/测试集\n",
    "    val_dataset=tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "    val_dataset=val_dataset.shuffle(1000).batch(batchsz).map(preprocess)\n",
    "    return train_dataset,val_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**a06.08**\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import os\n",
    "# dataset_path=keras.utils.get_file('auto-mpg.data','file://'+os.path.abspath('./data/auto-mpg.data'))\n",
    "# 下载汽车效能数据集\n",
    "dataset_path=keras.utils.get_file('auto-mpg.data','http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data')\n",
    "print(dataset_path)\n",
    "# 利用pandas读取数据集\n",
    "column_names=['MPG','Cylinders','Displacement','Horsepower','Weight','Acceleration','Model Year','Origin']\n",
    "raw_dataset=pd.read_csv(dataset_path,names=column_names,na_values='?',comment='\\t',sep=\" \",skipinitialspace=True)\n",
    "dataset=raw_dataset.copy()\n",
    "# 查看部分数据\n",
    "print(dataset.head())\n",
    "\n",
    "# 删除空字段数据项（含有空字段的行）\n",
    "print(dataset.isna().sum()) # 统计空白行\n",
    "dataset=dataset.dropna() # 删除空白数据项\n",
    "print(dataset.isna().sum()) # 再次统计空白行\n",
    "\n",
    "# 先弹出（删除并返回）origin这一列\n",
    "origin=dataset.pop('Origin')\n",
    "# 根据origin列来写入新的3个列\n",
    "dataset['USA']=(origin==1)*1.0\n",
    "dataset['Europe']=(origin==2)*1.0\n",
    "dataset['Japan']=(origin==3)*1.0\n",
    "print(dataset.tail()) # 查看表格后几项\n",
    "\n",
    "# 按照8:2比例划分训练/测试集\n",
    "train_dataset=dataset.sample(frac=.8,random_state=0)\n",
    "test_dataset=dataset.drop(train_dataset.index)\n",
    "\n",
    "# 将MPG字段作为标签，因此从train_dataset/test_dataset中移出\n",
    "train_labels=train_dataset.pop('MPG')\n",
    "test_labels=test_dataset.pop('MPG')\n",
    "\n",
    "# 统计训练集的各个字段的均值和标准差，并完成数据的标准化\n",
    "# 查看训练集的输入X的统计数据\n",
    "train_stats=train_dataset.describe()\n",
    "# print(train_stats)\n",
    "import sys\n",
    "try:\n",
    "    train_stats.pop('MPG')\n",
    "    # print(train_stats)\n",
    "except Exception:\n",
    "    pass\n",
    "# 标准化数据\n",
    "def norm(x,stats):\n",
    "    '''\n",
    "    标准化，减去每个字段的均值，并除以标准差\n",
    "    :param x:\n",
    "    :return:\n",
    "    '''\n",
    "    return (x-stats.loc['mean'])/stats.loc['std']\n",
    "normed_train_data=norm(train_dataset,train_stats) # 标准化训练集\n",
    "normed_test_data=norm(test_dataset,train_stats) # 标准化测试集\n",
    "print(normed_train_data.shape)\n",
    "print(normed_test_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "# 利用切分的训练集数据构建数据集对象：\n",
    "train_db=tf.data.Dataset.from_tensor_slices(\n",
    "    (normed_train_data.values,train_labels.values)) # 构建Dataset对象\n",
    "train_db=train_db.shuffle(100).batch(32) # 随机打散，批量化\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.常见网络层\n",
    "\n",
    "`tf.nn`模块中实现了常见网络层的接口函数。如`tf.nn.softmax`<br>\n",
    "`tf.keras.layers`提供了大量常见网络层的类，如全连接层、激活函数层、池化层、卷积层、循环神经网络层等\n",
    "\n",
    "更多见<https://tensorflow.google.cn/api_docs/python/tf/keras/layers/>\n",
    "\n",
    "例如Softmax层的创建："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.6590012 0.242433  0.0985659], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0.6590012 0.242433  0.0985659], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "x=tf.constant([2.,1.,.1])\n",
    "layer=layers.Softmax(axis=-1) # 创建Softmax层\n",
    "out=layer(x) # 调用Softmax的__call__进行前向计算\n",
    "print(out)\n",
    "\n",
    "out2=tf.nn.softmax(x)\n",
    "print(out2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Input**\n",
    "\n",
    "用于实例化一个Keras张量，充当类似一个占位符，可以用来限定每个输入样本的特征形状\n",
    "```python\n",
    "# tf.keras.Input( or\n",
    "tf.keras.layers.Input(\n",
    "    shape=None,\n",
    "    batch_size=None,\n",
    "    name=None,\n",
    "    dtype=None,\n",
    "    sparse=False,\n",
    "    tensor=None,\n",
    "    **kwargs\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(None, 32), dtype=float32)\n",
      "Tensor(\"Square:0\", shape=(None, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X=tf.keras.layers.Input(shape=(32,)) # 限定每个样本特征维度长度为32\n",
    "y=tf.square(X)\n",
    "print(X)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Dense**\n",
    "\n",
    "常用的全连接层\n",
    "```python\n",
    "tf.keras.layers.Dense(\n",
    "    units, activation=None, use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros', kernel_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    bias_constraint=None, **kwargs\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32)\n",
      "(4, 16)\n",
      "(4, 32)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(16,))) # 限定每个样本的特征长度为16\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "print(model.output_shape)\n",
    "X=tf.random.normal([4,16])\n",
    "print(X.shape)\n",
    "print(model(X).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Conv1D**\n",
    "\n",
    "一维卷积，常用作时间卷积\n",
    "```python\n",
    "tf.keras.layers.Conv1D(\n",
    "    filters, kernel_size, strides=1, padding='valid',\n",
    "    data_format='channels_last', dilation_rate=1, groups=1,\n",
    "    activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros', kernel_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    bias_constraint=None, **kwargs\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8, 32)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (4, 10, 128) # 4个样本，10个时间刻度，128维度的向量\n",
    "x = tf.random.normal(input_shape)\n",
    "y = tf.keras.layers.Conv1D(\n",
    "    32, 3, activation='relu',input_shape=input_shape[1:])(x)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Conv2D**\n",
    "\n",
    "2D卷积，常用作图像上的空域卷积\n",
    "```python\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters, kernel_size, strides=(1, 1), padding='valid',\n",
    "    data_format=None, dilation_rate=(1, 1), groups=1, activation=None,\n",
    "    use_bias=True, kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros', kernel_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    bias_constraint=None, **kwargs\n",
    ")\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 26, 26, 2)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (4, 28, 28, 3) # 4张28x28的RGB图片\n",
    "x = tf.random.normal(input_shape)\n",
    "y = tf.keras.layers.Conv2D(\n",
    "    2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**ReLU**\n",
    "\n",
    "```python\n",
    "tf.keras.layers.ReLU(\n",
    "    max_value=None, negative_slope=0, threshold=0, **kwargs\n",
    ")\n",
    "```\n",
    "默认计算规则是`max(x,0)`，否则：\n",
    "\n",
    "* `f(x) = max_value if x >= max_value`\n",
    "* `f(x) = x if threshold <= x < max_value`\n",
    "* `f(x) = negative_slope * (x - threshold) otherwise`\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 2.0]\n",
      "[0.0, 0.0, 0.0, 1.0]\n",
      "[-0.0, -0.0, 0.0, 2.0]\n",
      "[0.0, 0.0, 1.0, 1.5]\n",
      "[-6.0, -2.0, 0.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "layer = tf.keras.layers.ReLU()\n",
    "output = layer([-3.0, -1.0, 0.0, 2.0])\n",
    "print(list(output.numpy()))\n",
    "\n",
    "layer = tf.keras.layers.ReLU(max_value=1.0)\n",
    "output = layer([-3.0, -1.0, 0.0, 2.0])\n",
    "print(list(output.numpy()))\n",
    "\n",
    "layer = tf.keras.layers.ReLU(threshold=1.5)\n",
    "output = layer([-3.0, -1.0, 1.0, 2.0])\n",
    "print(list(output.numpy()))\n",
    "\n",
    "layer = tf.keras.layers.ReLU(threshold=0.5,max_value=1.5)\n",
    "output = layer([-3.0, -1.0, 1.0, 2.0])\n",
    "print(list(output.numpy()))\n",
    "\n",
    "layer = tf.keras.layers.ReLU(negative_slope=2.0)\n",
    "output = layer([-3.0, -1.0, 0.0, 2.0])\n",
    "print(list(output.numpy()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.网络容器\n",
    "对于常见的网络，需要手动调用每一层的类实例完成前向传播运算，当网络层数变得较深时，这一部分代码显得非常臃肿。可以通过 Keras 提供的网络容器 Sequential 将多个网络层封装成一个大网络模型，只需要调用网络模型的实例一次即可完成数据从第一层到最末层的顺序传播运算。\n",
    "\n",
    "如："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 23\n",
      "Trainable params: 23\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 4) for input Tensor(\"input_3:0\", shape=(None, 4), dtype=float32), but it was called on an input with incompatible shape (8, 3).\n",
      "Matrix size-incompatible: In[0]: [8,3], In[1]: [4,3] [Op:MatMul]\n",
      "(8, 2)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              multiple                  18        \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  12        \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               multiple                  0         \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(8, 3)\n",
      "name: dense_4/kernel:0\tshape: (5, 3)\n",
      "name: dense_4/bias:0\tshape: (3,)\n",
      "name: dense_5/kernel:0\tshape: (3, 3)\n",
      "name: dense_5/bias:0\tshape: (3,)\n"
     ]
    }
   ],
   "source": [
    "# 方式1\n",
    "network=tf.keras.Sequential([ # 封装为一个网络\n",
    "    layers.Input(shape=(4,)),\n",
    "    layers.Dense(3,activation=None),\n",
    "    layers.ReLU(),\n",
    "    layers.Dense(2,activation=None),\n",
    "    layers.ReLU(),\n",
    "])\n",
    "print(network.output_shape)\n",
    "network.summary()\n",
    "try:\n",
    "    x=tf.random.normal([8,3])\n",
    "    print(network(x).shape)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    x=tf.random.normal([8,4])\n",
    "    print(network(x).shape)\n",
    "\n",
    "# 方式2\n",
    "network1=tf.keras.Sequential([]) # 创建空的网络容器\n",
    "layers_num=2\n",
    "for _ in range(layers_num):\n",
    "    network1.add(layers.Dense(3))\n",
    "    network1.add(layers.ReLU())\n",
    "network1.build(input_shape=(None,5)) # 指定网络权重维度\n",
    "network1.summary()\n",
    "x=tf.random.normal([8,5])\n",
    "print(network1(x).shape)\n",
    "\n",
    "# 打印待优化参数\n",
    "for p in network1.trainable_variables:\n",
    "    print(f'name: {p.name}\\tshape: {p.shape}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "pid=os.getpid()\n",
    "!kill -9 $pid\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}