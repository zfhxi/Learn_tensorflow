{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.前言\n",
    "维度变换的原因：不同shape的矩阵相加需要统一shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.改变视图\n",
    "\n",
    "从不同的角度观察数据，产生不同的视图。如shape为[2,4,4,3]的张量A：\n",
    "1. 逻辑上，可以理解为2张图片，每张图片4行4列，每个位置有RGB3个通道的数据；\n",
    "2. 也可以理解为2个样本，每个样本的特征为长度48的向量\n",
    "\n",
    "内存没有维度这一概念，只以平铺方式写入内存，因此多维度的层级关系需要认为管理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95], shape=(96,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[ 0  1  2]\n",
      "   [ 3  4  5]\n",
      "   [ 6  7  8]\n",
      "   [ 9 10 11]]\n",
      "\n",
      "  [[12 13 14]\n",
      "   [15 16 17]\n",
      "   [18 19 20]\n",
      "   [21 22 23]]\n",
      "\n",
      "  [[24 25 26]\n",
      "   [27 28 29]\n",
      "   [30 31 32]\n",
      "   [33 34 35]]\n",
      "\n",
      "  [[36 37 38]\n",
      "   [39 40 41]\n",
      "   [42 43 44]\n",
      "   [45 46 47]]]\n",
      "\n",
      "\n",
      " [[[48 49 50]\n",
      "   [51 52 53]\n",
      "   [54 55 56]\n",
      "   [57 58 59]]\n",
      "\n",
      "  [[60 61 62]\n",
      "   [63 64 65]\n",
      "   [66 67 68]\n",
      "   [69 70 71]]\n",
      "\n",
      "  [[72 73 74]\n",
      "   [75 76 77]\n",
      "   [78 79 80]\n",
      "   [81 82 83]]\n",
      "\n",
      "  [[84 85 86]\n",
      "   [87 88 89]\n",
      "   [90 91 92]\n",
      "   [93 94 95]]]], shape=(2, 4, 4, 3), dtype=int32)\n",
      "140654373151744\n",
      "140654373151264\n",
      "1\n",
      "4\n",
      "(96,)\n",
      "(2, 4, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "x=tf.range(96) # 模拟生成一个向量数据\n",
    "x1=tf.reshape(x,[2,4,4,3]) # 改变视图，获得4D张量，存储未改变\n",
    "print(x)\n",
    "print(x1)\n",
    "print(id(x))\n",
    "print(id(x1))\n",
    "print(x.ndim)\n",
    "print(x1.ndim)\n",
    "print(x.shape)\n",
    "print(x1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`tf.reshape(x,[2,-1])`中的-1表示对应维度自动推导。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      " [48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      "  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95]], shape=(2, 48), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(x,[2,-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.增删维度\n",
    "\n",
    "增加维度并非修改数据，只是加一个长度为1的维度，改变数据的理解方式\n",
    " * 通过`tf.expand_dims(x,axis)`可以在指定的axis轴前插入一个新维度，axis可为负数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x=tf.random.uniform([28,28],maxval=10,dtype=tf.int32)\n",
    "x1=tf.expand_dims(x,axis=2)\n",
    "print(x1.shape)\n",
    "x2= tf.expand_dims(x1,axis=0)\n",
    "print(x2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "删除维度是增加维度的逆操作，只能输出长度为1的维度，不改变张量的存储。\n",
    "* 通过`tf.squeeze(x,axis)`删除指定轴的维度，如果axis不提供，默认删除所有长度为1的维度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "x3=tf.squeeze(x2,axis=0)\n",
    "print(x3.shape)\n",
    "x4=tf.squeeze(x3,axis=2)\n",
    "print(x4.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.交换维度\n",
    "\n",
    "使用`tf.transpose(x,perm)`完成，perm表示新的维度顺序List\n",
    "注：维度交换后，张量的存储顺序也改变，比改变视图的计算代价更高\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "x=tf.random.normal([2,32,32,3])\n",
    "x1=tf.transpose(x,perm=[0,3,1,2])\n",
    "print(x1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.复制数据\n",
    "\n",
    "典型的操作是先增加长度为1的维度，然后在该维度进行复制若干份数据\n",
    "* `tf.tile(x,multiples)`，multiples表示每个维度上复制的倍数，1表示不复制，2表示原来长度的2倍。\n",
    "* `tf.tile`会创建一个新的张量来保存复制后的张量，由于复制操作涉及大量数据的读写IO运算，计算代价较高。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3 7], shape=(2,), dtype=int32)\n",
      "tf.Tensor([[3 7]], shape=(1, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[3 7]\n",
      " [3 7]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "b=tf.constant([3,7])\n",
    "print(b)\n",
    "b1=tf.expand_dims(b,axis=0)\n",
    "print(b1)\n",
    "b2=tf.tile(b1,multiples=[2,1])\n",
    "print(b2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.Broadcasting\n",
    "\n",
    "广播机制，相对于`tf.tile`是一种轻量级复制手段，在逻辑上扩展张量数据的形状，但只会在需要时才执行实际存储复制操作。\n",
    "* Broadcasting 机制的核心思想是普适性,即同一份数据能普遍适合于其他位置。在验证普适性之前,需要先将张量 shape 靠右对齐,然后进行普适性判断:对于长度为 1 的维度,默认这个数据普遍适合于当前维度的其他位置;对于不存在的维度,则在增加新维度后默认当前数据也是普适于新维度的,从而可以扩展为更多维度数、任意长度的张量形状。\n",
    "* 对于用户而言，Broadcasting和tf.tile复制的最终效果一样，操作对用户透明，但前者节省资源\n",
    "* Broadcasting流程：\n",
    "\n",
    "![](https://github.com/zfhxi/Learn_tensorflow/blob/master/TensorFlowDL/ch04-TensorFlow%E5%9F%BA%E7%A1%80/img/03.png?raw=true)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "考虑$Y=X@W+b$，$X@W$的shape为\\[2,3\\]，b的shape为\\[3\\]，使用广播机制复制数据如下："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "X=tf.random.normal([2,4])\n",
    "W=tf.random.normal([4,3])\n",
    "b=tf.random.normal([3])\n",
    "Y=X@W+b\n",
    "print(Y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这里进行`+`操作时，自动调用了`tf.broadcast_to(b,[2,3])`的Broadcasting机制\n",
    "\n",
    "也可以主动使用`tf.broadcast_to(x,new_shape)`显式地进行自动扩展"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1)\n",
      "(2, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "A=tf.random.normal([32,1])\n",
    "print(A.shape)\n",
    "A1=tf.broadcast_to(A,[2,32,32,3])\n",
    "print(A1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "普适性失败案例：\n",
    "\n",
    "![](https://github.com/zfhxi/Learn_tensorflow/blob/master/TensorFlowDL/ch04-TensorFlow%E5%9F%BA%E7%A1%80/img/03.png?raw=true)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incompatible shapes: [32,2] vs. [2,32,32,4] [Op:BroadcastTo]\n"
     ]
    }
   ],
   "source": [
    "A=tf.random.normal([32,2])\n",
    "try:\n",
    "    A1=tf.broadcast_to(A,[2,32,32,4])\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "pid=os.getpid()\n",
    "!kill -9 $pid\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}